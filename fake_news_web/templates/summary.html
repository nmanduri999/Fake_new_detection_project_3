<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->

  <title>Real or fake news?</title>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
  <link rel="stylesheet" href="../static/css/style.css">
</head>

<body>
    <div class="wrapper3">
        <nav class="navbar">
            <ul>
              <li><a href="index.html">Home</a></li>
              <li><a href="methods.html">Methods</a></li>
              <li><a class="active" href="summary.html">Summary</a></li>
            </ul>
        </nav>
        <div class="center">
            <h1>SUM IT UP!</h1>
        </div>
    </div>

    <br>
    <div class="container-fluid padding">
		<div class="row welcome text-center">

			<br>
			<div class="col-12">
                <h2>Methods, Statistics and Databases</h2>
                <hr style="border: 1px solid #F8F8FF;" />
				<p class="lead">
					Fake News Detection inlcuded methods in Python, sklearn, HTML/CSS, and Regular Expression(RE), and Machine Learning.
                    We obtained our datasets from different websites, including combining datasets and Natural Language Processing (NLP) to preprocess
                    our datasets.
                </p>
                <a target="_blank" href="https://github.com/nmanduri999/Fake_news_detection_project_3">View Github</a>
                <br>

				<!-- <a target="_blank" href="https://github.com/nmanduri999/Fake_news_detection_project_3" class="btn btn-primary">View Github</a> -->
                <br>
                <h2>Conclusion</h2>
                <hr style="border: 1px solid #F8F8FF;" />
				<p class="lead">
                    Text analysis is a particularly interesting application of machine learning since it allows computers to make sense of non-numeric
                    data. We learned a lot about the pre-processing of text. We learned that NLTK was the best way to get the output we wanted and settled
                    with the use of TFidfvectorizer as the vectorizer that we used . In terms of model-building, training and testing the data we used Jupyter
                    notebooks and also utilized Google Colab to run our notebooks.
                </p>
                <p class="lead">
                    The models' accuracy was high but train dataset doesn't include all types of writing styles, therefore, sometimes the predictions were not as expected.
                </p>
                <h2>Challenges</h2>
                <hr style="border: 1px solid #F8F8FF;" />
                <br>

				<p class="lead">
					It took 3 hours for CNN model to run on Colab.
                </p>
                <p class="lead">
					We usally ran out of GPU storage and had to start over many times.
                </p>
                <br>
                
                <h2>Improvements</h2>
                <hr style="border: 1px solid #F8F8FF;" />
                <br>
                <p class="lead">
                    Larger dataset spanning a longer time period
                </p>
                <p class="lead">
                    Try other kinds of models
                </p>

                <hr style="border: 1px solid #F8F8FF;" />
			    <div class="col-12">
                <h2>References</h2>
                <hr style="border: 1px solid #F8F8FF;" />
				<a target="_blank" href="https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset">Fake and real news dataset</a>
				<br>
				<a target="_blank" href="hhttps://www.kaggle.com/c/fake-news/data?select=train.csv">Fake News</a>
			</div>

            </div>

            </div>
            
			
		</div>
	</div>

</body>
</html>
